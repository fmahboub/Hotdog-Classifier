{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "(Complete) Problem_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fmahboub/Hotdog-Classifier/blob/master/TransferLearning(Mobilenet).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tpig6xnGU5Q",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "This problem's purpose is to build a convolutional neural network to classify images as hot dogs or not-hot dogs. This is the same problem as seen in the HBO TV show \"Silicon Valley\" (https://www.youtube.com/watch?v=pqTntG1RXSY).  We'll be using the dataset put together by a user on Kaggle (https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog) which contains 498 training images and 500 test images.\n",
        "\n",
        "A simple CNN is given below.  Due to the small sample size it has a very poor test set accuracy (around 55\\%). The task was to build a CNN that can beat this test set accuracy by a large margin (better than or equal to 70\\% test set accuracy).\n",
        "\n",
        "This was done by using transfer learning and the MobileNet pretrained network. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMj4keK5GU5a",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-03T22:20:48.270603Z",
          "start_time": "2019-01-03T22:20:44.658149Z"
        },
        "id": "pL91vBWRGU5d",
        "colab_type": "code",
        "outputId": "c3046a9e-97ef-4320-f34f-74a985731a36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, UpSampling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_3DeX7vGU5m",
        "colab_type": "text"
      },
      "source": [
        "## Loading Hotdog-Not-Hotdog Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7hGl3-aItSo",
        "colab_type": "code",
        "outputId": "e241cfe9-f864-425e-fd54-b7d95dd45159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download files\n",
        "!wget https://briankeng.com/files/hotdog.tar.gz\n",
        "!tar -xvzf hotdog.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-29 14:59:42--  https://briankeng.com/files/hotdog.tar.gz\n",
            "Resolving briankeng.com (briankeng.com)... 207.38.86.247, 2605:de00:1:1:4a:31:0:b0\n",
            "Connecting to briankeng.com (briankeng.com)|207.38.86.247|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46732258 (45M) [application/x-tar]\n",
            "Saving to: ‘hotdog.tar.gz.2’\n",
            "\n",
            "hotdog.tar.gz.2     100%[===================>]  44.57M  57.9MB/s    in 0.8s    \n",
            "\n",
            "2020-01-29 14:59:43 (57.9 MB/s) - ‘hotdog.tar.gz.2’ saved [46732258/46732258]\n",
            ,
            "hotdog/train/not_hot_dog/4770.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-03T22:20:48.278288Z",
          "start_time": "2019-01-03T22:20:48.273274Z"
        },
        "id": "_PnwVtTiGU5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Re-scaled dimensions of our images.\n",
        "img_width, img_height = 122, 122\n",
        "\n",
        "train_data_dir = 'hotdog/train'\n",
        "test_data_dir = 'hotdog/test'\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ_D1of_kK3Q",
        "colab_type": "code",
        "outputId": "dca0665a-cf4d-4f4f-bb96-95b8a2e1ce6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "mobilenet_base = MobileNet(weights='imagenet', include_top=False)\n",
        "mobilenet_base"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.training.Model at 0x7f9a5f792da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2p61NreGU5x",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-03T22:27:08.034238Z",
          "start_time": "2019-01-03T22:27:07.809397Z"
        },
        "id": "4qR8gB1eGU5z",
        "colab_type": "code",
        "outputId": "7a48140f-8f6a-4fa3-daa9-649aed6e7c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "def mymodel():\n",
        "    ''' Improve this model! \n",
        "        Simple model from: https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d\n",
        "    '''\n",
        "    model = Sequential()\n",
        "    model.add(UpSampling2D(size=(2,2), input_shape=input_shape))\n",
        "    model.add(mobilenet_base)\n",
        "    \n",
        "    model.add(Conv2D(128, (7, 7),activation='sigmoid', padding='same'))\n",
        "    model.add(Dropout(0.45))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(90,activation='relu'))\n",
        "    model.add(Dropout(0.45))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  # Freeze layers in the base model (i.e. only train the classifier)\n",
        "    for layer in mobilenet_base.layers:\n",
        "      layer.trainable = False\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy', metrics=['accuracy'], \n",
        "                  optimizer=keras.optimizers.Adam(lr=0.0002))\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Test function\n",
        "mymodel().summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "up_sampling2d_1 (UpSampling2 (None, 244, 244, 3)       0         \n",
            "_________________________________________________________________\n",
            "mobilenet_1.00_224 (Model)   multiple                  3228864   \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 7, 7, 128)         6422656   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 90)                103770    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 91        \n",
            "=================================================================\n",
            "Total params: 9,755,381\n",
            "Trainable params: 6,526,517\n",
            "Non-trainable params: 3,228,864\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLWMMurWGU56",
        "colab_type": "text"
      },
      "source": [
        "### Loading data on the fly\n",
        "\n",
        "We load the data directly from the images on disk via these Keras helper functions (`ImageDataGenerator` and `flow_from_directory`). It performs two transformations: \n",
        "\n",
        "* Rescaling pixels to be between [0, 1]\n",
        "* Resizing images to be in `img_width`x`img_height` (150x150)\n",
        "\n",
        "During training for each batch, the images are read from disk on the fly, loaded into memory and then the transformations are applied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-03T22:27:10.350862Z",
          "start_time": "2019-01-03T22:27:10.121375Z"
        },
        "id": "Xu_v10EUGU58",
        "colab_type": "code",
        "outputId": "8ad823d9-634a-4805-ed70-00c71652c0cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# You may optionally change these parameters\n",
        "batch_size = 50\n",
        "epochs = 15\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "# Data parameters (DO NOT MODIFY)\n",
        "num_train_samples = 498\n",
        "num_test_samples = 500\n",
        "\n",
        "# Data generators (DO NOT MODIFY)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 498 images belonging to 2 classes.\n",
            "Found 500 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_qqt8T-sPBZ",
        "colab_type": "code",
        "outputId": "99493bf6-a587-4baf-c029-8fbdccc03a25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "model = mymodel()\n",
        "model.fit_generator(train_generator, callbacks=[], \n",
        "                            steps_per_epoch=num_train_samples // batch_size,\n",
        "                            epochs=epochs, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/15\n",
            "9/9 [==============================] - 7s 799ms/step - loss: 1.0207 - acc: 0.5473\n",
            "Epoch 2/15\n",
            "9/9 [==============================] - 2s 190ms/step - loss: 0.5011 - acc: 0.7788\n",
            "Epoch 3/15\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 0.3778 - acc: 0.8511\n",
            "Epoch 4/15\n",
            "9/9 [==============================] - 2s 207ms/step - loss: 0.2398 - acc: 0.9193\n",
            "Epoch 5/15\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 0.2468 - acc: 0.9063\n",
            "Epoch 6/15\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 0.1451 - acc: 0.9644\n",
            "Epoch 7/15\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.1083 - acc: 0.9755\n",
            "Epoch 8/15\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 0.0908 - acc: 0.9711\n",
            "Epoch 9/15\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.0599 - acc: 0.9844\n",
            "Epoch 10/15\n",
            "9/9 [==============================] - 2s 207ms/step - loss: 0.0419 - acc: 0.9955\n",
            "Epoch 11/15\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 0.0292 - acc: 1.0000\n",
            "Epoch 12/15\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 0.0209 - acc: 0.9978\n",
            "Epoch 13/15\n",
            "9/9 [==============================] - 2s 206ms/step - loss: 0.0172 - acc: 1.0000\n",
            "Epoch 14/15\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 0.0222 - acc: 0.9977\n",
            "Epoch 15/15\n",
            "9/9 [==============================] - 2s 206ms/step - loss: 0.0285 - acc: 0.9978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a5f61b780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZnYmzRAtCag",
        "colab_type": "code",
        "outputId": "f142d914-bff0-44aa-9e01-c85dbb0fb67f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "scores = []\n",
        "model.evaluate_generator(test_generator, steps=num_test_samples // batch_size,\n",
        "                                               verbose=1)\n",
        "scores.append(model.evaluate_generator(test_generator, \n",
        "                                               steps=num_test_samples // batch_size,\n",
        "                                               verbose=0))\n",
        "print(' * Test set Loss: %.4f, Accuracy: %.4f' % (scores[-1][0], scores[-1][1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 2s 241ms/step\n",
            " * Test set Loss: 0.3016, Accuracy: 0.8640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-03T22:41:10.807043Z",
          "start_time": "2019-01-03T22:27:10.921699Z"
        },
        "scrolled": false,
        "id": "KR1ccoXzGU6C",
        "colab_type": "code",
        "outputId": "549f717c-8da2-4725-8ce8-62db33aa750b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "def evaluate_model(runs=5):\n",
        "    ''' DO NOT MODIFY THIS FUNCTION '''\n",
        "    scores = [] \n",
        "    for i in range(runs):\n",
        "        print('Executing run %d' % (i+1))\n",
        "        model = mymodel()\n",
        "        model.fit_generator(train_generator,\n",
        "                            callbacks=[],\n",
        "                            steps_per_epoch=num_train_samples // batch_size,\n",
        "                            epochs=epochs, verbose=0)\n",
        "        print(' * Evaluating model on test set')\n",
        "        scores.append(model.evaluate_generator(test_generator, \n",
        "                                               steps=num_test_samples // batch_size,\n",
        "                                               verbose=0))\n",
        "        print(' * Test set Loss: %.4f, Accuracy: %.4f' % (scores[-1][0], scores[-1][1]))\n",
        "        \n",
        "    accuracies = [score[1] for score in scores]     \n",
        "    return np.mean(accuracies), np.std(accuracies)\n",
        "        \n",
        "mean_accuracy, std_accuracy = evaluate_model(runs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing run 1\n",
            " * Evaluating model on test set\n",
            " * Test set Loss: 0.4197, Accuracy: 0.8120\n",
            "Executing run 2\n",
            " * Evaluating model on test set\n",
            " * Test set Loss: 0.3230, Accuracy: 0.8580\n",
            "Executing run 3\n",
            " * Evaluating model on test set\n",
            " * Test set Loss: 0.3359, Accuracy: 0.8500\n",
            "Executing run 4\n",
            " * Evaluating model on test set\n",
            " * Test set Loss: 0.2734, Accuracy: 0.8820\n",
            "Executing run 5\n",
            " * Evaluating model on test set\n",
            " * Test set Loss: 0.3408, Accuracy: 0.8440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-03T22:41:27.196711Z",
          "start_time": "2019-01-03T22:41:27.184542Z"
        },
        "id": "KsFw6WswGU6I",
        "colab_type": "code",
        "outputId": "1ae40006-4f0e-4412-90fc-a6e951762813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " # You will be evaluated on your mean test set accuracy over 5 runs\n",
        "print('Mean test set accuracy over 5 runs: %.4f +/- %.4f' % (mean_accuracy, std_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean test set accuracy over 5 runs: 0.8492 +/- 0.0226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGQCYZOkGU6O",
        "colab_type": "text"
      },
      "source": [
        "# Describe 3 Changes\n",
        "\n",
        "Describe three modifications you made to your network that are not included in this notebook (1-3 paragraphs each) and the effect they had on the test set performance.  Not all of the changes need to be in your final version (e.g. some of the changes may have not improved the test set performance).\n",
        "\n",
        "1. Change one...\n",
        "2. Change two...\n",
        "3. Change three..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpU00jvZhElM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# No Changes: 0.5584 +/- 0.0320\n",
        "# RMS Prop --> Adam: 0.5772 +/- 0.0230\n",
        "# ^ + Added UpSampling2D(1x1) & MobileNet Layer and Removed 2 Convolutional Layers and 2 MaxPooling Layers: 0.8048 +/- 0.0312\n",
        "# ^ + Epochs to 12 and Set size of image to 122x122 and increased UpSampling2D to (2x2): 0.8284 +/- 0.0306\n",
        "# ^ + changed width of dense layer to 90: 0.8480 +/- 0.0176\n",
        "# ^ + changed number of filters on convolutional layer to 128 and changed kernal size to 7x7\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvpf9FSmp6gp",
        "colab_type": "code",
        "outputId": "6ed4869d-2d72-4164-d923-cd794b1805d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"increase dropout on dense layer to 0.65 did not change much\"\n",
        "\"increase kernel size on convolutional layer to 4x4, no change\"\n",
        "\"decreased number of filters on convolutinal layer to 32, no change\"\n",
        "\"increased number of filters to 128 on convolutional layer + increased and decreased kernal size\"\n",
        "\"added dropout layer (0.3) after maxpooling layer, no improvement\"\n",
        "\"added dropout layer (0.3) before maxpooling layer, no improvement\"\n",
        "\"added dropout layer (0.5) before maxpooling layer, no improvement\"\n",
        "\"added dropout layer (0.5) before maxpooling layer and increased epochs to 15, no improvement\"\n",
        "\"added dropout layer (0.5) before maxpooling layer and increased epochs to 15 and increased conv layer filters to 128, ...\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'added dropout layer (0.5) before maxpooling layer and increased epochs to 15 and increased conv layer filters to 128, ...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}
